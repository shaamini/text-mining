{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4b13c5",
   "metadata": {},
   "source": [
    "# Read Necessary Files & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cbc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pickle\n",
    "import ast\n",
    "import bitermplus as btm\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad208a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_india_df = pd.read_csv(\"demo files/india-v1-preprocessed-overall.csv\")\n",
    "filtered_india_df = pd.read_csv('demo files/sentiment_labelled_india_NB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c466dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For obj & sub\n",
    "v = CountVectorizer()\n",
    "X_whole_data = v.fit_transform(whole_india_df.translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717bf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For topic modelling - BITERM\n",
    "texts = filtered_india_df['words_processed_noun']\n",
    "\n",
    "new_text_noun = []\n",
    "\n",
    "for row in texts:\n",
    "    new_row = ast.literal_eval(row)\n",
    "    new_row = \" \".join(new_row)\n",
    "    new_text_noun.append(new_row)\n",
    "    \n",
    "filtered_india_df['new_text_noun'] = new_text_noun\n",
    "texts = filtered_india_df['new_text_noun']\n",
    "\n",
    "stop_words = ['vaccine','people','couid', 'lot', 'thing', 'amp', 'day', 'week', 'time', 'year', 'vaccination',\n",
    "             'month', 'number', 'part', 'hour', 'shit', 'person', 'go', 'pfizer','room', 'man', 'word', 'other', \n",
    "              'point', 'today', 'way', 'yesterday', 'lot', 'one', 'need', 'love', 'covidvaccine', 'use', 'bit',\n",
    "             'idiot', 'thank', 'shot', 'tomorrow', 'dose', 'mask', 'life']\n",
    "\n",
    "def get_dominant_df(p_zd):\n",
    "    scores = [[]]\n",
    "    \n",
    "    for score in p_zd[0]:\n",
    "        scores[0].append(score)\n",
    "        \n",
    "    topicnames = [\"Education\", \"Healthcare Sector\", \"Covid Cases Updates\", \"How to stay safe\", \"Travelling\", \"Economic/Political Impact\", \n",
    "                  \"Vaccination Appointment\",\"Side Effects/Symptoms\", \"Undetermined\"]\n",
    "    docnames = [\"Tweet\"]\n",
    "    df = pd.DataFrame(np.round(scores, 5), columns=topicnames, index=docnames)\n",
    "    \n",
    "    if np.amax(df.values) > 0.3:\n",
    "        dominant_topic = topicnames[np.argmax(df.values, axis=1)[0]]\n",
    "        df['dominant_topic'] = dominant_topic\n",
    "    else:\n",
    "        df['dominant_topic'] = \"Unclassified\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c0bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For topic modelling - GSDMM\n",
    "def get_dominant_df_gsdmm(a_list):\n",
    "    scores = [[]]\n",
    "    \n",
    "    for score in a_list:\n",
    "        scores[0].append(score)\n",
    "        \n",
    "    topicnames = [\"Covid Cases Updates\", \"Economic/Political Impact\", \"Vaccination Appointment\", \"Travelling\", \"Side Effects/Symptoms\",\"Education\"]\n",
    "    docnames = [\"Tweet\"]\n",
    "    df = pd.DataFrame(np.round(scores, 5), columns=topicnames, index=docnames)\n",
    "    dominant_topic = topicnames[np.argmax(df.values, axis=1)[0]]\n",
    "    df['dominant_topic'] = dominant_topic\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c676f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For sentiment classification\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "whole_data = cv.fit_transform(filtered_india_df['new_text'].values.astype('U'))\n",
    "\n",
    "def get_sentiment(value):\n",
    "    if value == 0:\n",
    "        return \"NEGATIVE\"\n",
    "    elif value == \"1\":\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab318dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = [\"so if you all keep asking us do rtpcr everytime, even after being fully vaccinated- what has point yes, you can get covid even after vaccination but if u have do test everytime u travel even within state, it is all never ending, money eating business loop.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719704c3",
   "metadata": {},
   "source": [
    "# Objective & Subjective Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8965e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = open(\"pickles/india/india_subj.pickle\", \"rb\") #binary read\n",
    "model = pickle.load(model_saved)\n",
    "model_saved.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6495b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_transformed = v.transform(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "621f0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = model.predict(tweet_transformed)\n",
    "print(\"The predicted class is: \" + str(predicted_class[0]).upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd7088",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027976d8",
   "metadata": {},
   "source": [
    "## Biterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c25895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = open(\"pickles/india/india_biterm.model\", \"rb\") #binary read\n",
    "model = pickle.load(model_saved)\n",
    "model_saved.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be68fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_noun_strlist = [\" \".join(ast.literal_eval(filtered_india_df[filtered_india_df[\"translated\"] == tweet[0]][\"words_processed_noun\"].iloc[0]))]\n",
    "tweet_noun_strlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, vocabulary, vocab_dict = btm.get_words_freqs(texts, stop_words=stop_words)\n",
    "new_docs_vec = btm.get_vectorized_docs(tweet_noun_strlist, vocabulary)\n",
    "p_zd = model.transform(new_docs_vec)\n",
    "dominant_df = get_dominant_df(p_zd)\n",
    "dominant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20a637a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dominant topic is: \" + str(dominant_df[\"dominant_topic\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62530bd4",
   "metadata": {},
   "source": [
    "## GSDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786dff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_saved = open(\"pickles/india_gsdmm.pickle\", \"rb\") #binary read\n",
    "# model = pickle.load(model_saved)\n",
    "# model_saved.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3797bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_nouns_list = ast.literal_eval(filtered_india_df[filtered_india_df[\"translated\"] == tweet[0]][\"words_processed_noun\"].iloc[0])\n",
    "# tweet_nouns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f472097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dominant_df = get_dominant_df_gsdmm(model.score(tweet_nouns))\n",
    "# dominant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0375d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The dominant topic is: \" + str(dominant_df[\"dominant_topic\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44563ac3",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64adb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = open(\"pickles/india/india_sentiment.model\", \"rb\") #binary read\n",
    "model = pickle.load(model_saved)\n",
    "model_saved.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "161a7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_transformed = cv.transform(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "004f7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = model.predict(tweet_transformed)\n",
    "sentiment = get_sentiment(predicted_class[0])\n",
    "print(\"The predicted class is: \" + sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
