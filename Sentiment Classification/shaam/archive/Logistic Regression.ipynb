{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206a921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4d2378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>new_text</th>\n",
       "      <th>languages</th>\n",
       "      <th>new_text_after_translation</th>\n",
       "      <th>pos_tagged_words</th>\n",
       "      <th>words_processed_all</th>\n",
       "      <th>words_processed_noun_adj_verb_adv</th>\n",
       "      <th>words_processed_noun</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher i got my second pfizer vaccine shot may 1...</td>\n",
       "      <td>cher i got my second pfizer vaccine shot may 1...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>cher i got my second pfizer vaccine shot may 1...</td>\n",
       "      <td>[('cher', 'NN'), ('i', 'NN'), ('got', 'VBD'), ...</td>\n",
       "      <td>['cher', 'get', 'second', 'pfizer', 'vaccine',...</td>\n",
       "      <td>['cher', 'get', 'second', 'pfizer', 'vaccine',...</td>\n",
       "      <td>['cher', 'pfizer', 'vaccine', 'cher', 'guess',...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ô£ø√º√≠√¢dp'ed by pfizer april Ô£ø√º√≤√•</td>\n",
       "      <td>syringedp'ed by pfizer april relieved_face</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>syringedp'ed by pfizer april relieved_face</td>\n",
       "      <td>[('syringe', 'NN'), ('ed', 'NN'), ('by', 'IN')...</td>\n",
       "      <td>['syringe', 'ed', 'pfizer', 'april']</td>\n",
       "      <td>['syringe']</td>\n",
       "      <td>['syringe']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ô£ø√º√´√ßÔ£ø√º√®¬∫ double shot pfizer</td>\n",
       "      <td>thumbs_upmedium-light_skin_tone double shot pf...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>thumbs_upmedium-light_skin_tone double shot pf...</td>\n",
       "      <td>[('double', 'RB'), ('shot', 'JJ'), ('pfizer', ...</td>\n",
       "      <td>['double', 'shot', 'pfizer']</td>\n",
       "      <td>['double', 'shot', 'pfizer']</td>\n",
       "      <td>['shot', 'pfizer']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>couple things. my wife has ra. takes plaquenil...</td>\n",
       "      <td>couple things. my wife has ra. takes plaquenil...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>couple things. my wife has ra. takes plaquenil...</td>\n",
       "      <td>[('couple', 'NN'), ('things', 'NNS'), ('my', '...</td>\n",
       "      <td>['couple', 'thing', 'wife', 'ra', 'take', 'pla...</td>\n",
       "      <td>['couple', 'thing', 'wife', 'take', 'plaquenil...</td>\n",
       "      <td>['couple', 'thing', 'wife', 'plaquenil', 'prob...</td>\n",
       "      <td>{'neg': 0.056, 'neu': 0.887, 'pos': 0.057, 'co...</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great, me too back april. pfizer 2 shots</td>\n",
       "      <td>great, me too back april. pfizer 2 shots</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>great, me too back april. pfizer 2 shots</td>\n",
       "      <td>[('great', 'JJ'), ('me', 'PRP'), ('too', 'RB')...</td>\n",
       "      <td>['great', 'back', 'april', 'pfizer', 'two', 's...</td>\n",
       "      <td>['great', 'pfizer', 'shot']</td>\n",
       "      <td>['pfizer', 'shot']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.594, 'pos': 0.406, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>we‚Äö√Ñ√¥re at north high school today until 5...</td>\n",
       "      <td>we‚Äö√Ñ√¥re at north high school today until 5...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>we‚Äö√Ñ√¥re at north high school today until 5...</td>\n",
       "      <td>[('we', 'PRP'), ('i', 'VBP'), ('re', 'VBP'), (...</td>\n",
       "      <td>['north', 'high_school', 'today', 'come', 'get...</td>\n",
       "      <td>['north', 'today', 'come', 'get', 'free', 'pfi...</td>\n",
       "      <td>['north', 'today', 'pfizer', 'vaccine', 'year'...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.845, 'pos': 0.155, 'comp...</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>y‚Äö√Ñ√¥all please get vaccinated. . . . . * d...</td>\n",
       "      <td>y‚Äö√Ñ√¥all please get vaccinated. . . . . * d...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>y‚Äö√Ñ√¥all please get vaccinated. . . . . * d...</td>\n",
       "      <td>[('y', 'NN'), ('i', 'NN'), ('all', 'DT'), ('pl...</td>\n",
       "      <td>['please', 'get', 'vaccinated', 'disclaimer', ...</td>\n",
       "      <td>['get', 'vaccinated', 'disclaimer', 'pfizer', ...</td>\n",
       "      <td>['disclaimer', 'pfizer', 'stock']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.753, 'pos': 0.247, 'comp...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>disappointed you are blame only unvaccinated c...</td>\n",
       "      <td>disappointed you are blame only unvaccinated c...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>disappointed you are blame only unvaccinated c...</td>\n",
       "      <td>[('disappointed', 'VBN'), ('you', 'PRP'), ('ar...</td>\n",
       "      <td>['disappointed', 'blame', 'vaccinated', 'crowd...</td>\n",
       "      <td>['disappointed', 'blame', 'vaccinated', 'crowd...</td>\n",
       "      <td>['blame', 'delta', 'covid', 'case', 'vaccine']</td>\n",
       "      <td>{'neg': 0.174, 'neu': 0.727, 'pos': 0.099, 'co...</td>\n",
       "      <td>-0.4753</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>be fair, cdc et al have always said pfizer or ...</td>\n",
       "      <td>be fair, cdc et al have always said pfizer or ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>be fair, cdc et al have always said pfizer or ...</td>\n",
       "      <td>[('be', 'VB'), ('fair', 'JJ'), ('cac', 'JJ'), ...</td>\n",
       "      <td>['fair', 'cac', 'et_al', 'always', 'say', 'pfi...</td>\n",
       "      <td>['fair', 'cac', 'et_al', 'always', 'say', 'pfi...</td>\n",
       "      <td>['cac', 'et_al', 'pfizer', 'vaccination', 'cha...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.888, 'pos': 0.112, 'comp...</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>if it has been 21 days since your first pfizer...</td>\n",
       "      <td>if it has been 21 days since your first pfizer...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>if it has been 21 days since your first pfizer...</td>\n",
       "      <td>[('if', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ...</td>\n",
       "      <td>['twentynine', 'day', 'since', 'first', 'pfize...</td>\n",
       "      <td>['twentynine', 'day', 'first', 'pfizer', 'shoo...</td>\n",
       "      <td>['twentynine', 'day', 'pfizer', 'day', 'shot',...</td>\n",
       "      <td>{'neg': 0.052, 'neu': 0.948, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     cher i got my second pfizer vaccine shot may 1...   \n",
       "1              Ô£ø√º√≠√¢dp'ed by pfizer april Ô£ø√º√≤√•   \n",
       "2                 Ô£ø√º√´√ßÔ£ø√º√®¬∫ double shot pfizer   \n",
       "3     couple things. my wife has ra. takes plaquenil...   \n",
       "4              great, me too back april. pfizer 2 shots   \n",
       "...                                                 ...   \n",
       "1495  we‚Äö√Ñ√¥re at north high school today until 5...   \n",
       "1496  y‚Äö√Ñ√¥all please get vaccinated. . . . . * d...   \n",
       "1497  disappointed you are blame only unvaccinated c...   \n",
       "1498  be fair, cdc et al have always said pfizer or ...   \n",
       "1499  if it has been 21 days since your first pfizer...   \n",
       "\n",
       "                                               new_text languages  \\\n",
       "0     cher i got my second pfizer vaccine shot may 1...   ENGLISH   \n",
       "1            syringedp'ed by pfizer april relieved_face   ENGLISH   \n",
       "2     thumbs_upmedium-light_skin_tone double shot pf...   ENGLISH   \n",
       "3     couple things. my wife has ra. takes plaquenil...   ENGLISH   \n",
       "4              great, me too back april. pfizer 2 shots   ENGLISH   \n",
       "...                                                 ...       ...   \n",
       "1495  we‚Äö√Ñ√¥re at north high school today until 5...   ENGLISH   \n",
       "1496  y‚Äö√Ñ√¥all please get vaccinated. . . . . * d...   ENGLISH   \n",
       "1497  disappointed you are blame only unvaccinated c...   ENGLISH   \n",
       "1498  be fair, cdc et al have always said pfizer or ...   ENGLISH   \n",
       "1499  if it has been 21 days since your first pfizer...   ENGLISH   \n",
       "\n",
       "                             new_text_after_translation  \\\n",
       "0     cher i got my second pfizer vaccine shot may 1...   \n",
       "1            syringedp'ed by pfizer april relieved_face   \n",
       "2     thumbs_upmedium-light_skin_tone double shot pf...   \n",
       "3     couple things. my wife has ra. takes plaquenil...   \n",
       "4              great, me too back april. pfizer 2 shots   \n",
       "...                                                 ...   \n",
       "1495  we‚Äö√Ñ√¥re at north high school today until 5...   \n",
       "1496  y‚Äö√Ñ√¥all please get vaccinated. . . . . * d...   \n",
       "1497  disappointed you are blame only unvaccinated c...   \n",
       "1498  be fair, cdc et al have always said pfizer or ...   \n",
       "1499  if it has been 21 days since your first pfizer...   \n",
       "\n",
       "                                       pos_tagged_words  \\\n",
       "0     [('cher', 'NN'), ('i', 'NN'), ('got', 'VBD'), ...   \n",
       "1     [('syringe', 'NN'), ('ed', 'NN'), ('by', 'IN')...   \n",
       "2     [('double', 'RB'), ('shot', 'JJ'), ('pfizer', ...   \n",
       "3     [('couple', 'NN'), ('things', 'NNS'), ('my', '...   \n",
       "4     [('great', 'JJ'), ('me', 'PRP'), ('too', 'RB')...   \n",
       "...                                                 ...   \n",
       "1495  [('we', 'PRP'), ('i', 'VBP'), ('re', 'VBP'), (...   \n",
       "1496  [('y', 'NN'), ('i', 'NN'), ('all', 'DT'), ('pl...   \n",
       "1497  [('disappointed', 'VBN'), ('you', 'PRP'), ('ar...   \n",
       "1498  [('be', 'VB'), ('fair', 'JJ'), ('cac', 'JJ'), ...   \n",
       "1499  [('if', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ...   \n",
       "\n",
       "                                    words_processed_all  \\\n",
       "0     ['cher', 'get', 'second', 'pfizer', 'vaccine',...   \n",
       "1                  ['syringe', 'ed', 'pfizer', 'april']   \n",
       "2                          ['double', 'shot', 'pfizer']   \n",
       "3     ['couple', 'thing', 'wife', 'ra', 'take', 'pla...   \n",
       "4     ['great', 'back', 'april', 'pfizer', 'two', 's...   \n",
       "...                                                 ...   \n",
       "1495  ['north', 'high_school', 'today', 'come', 'get...   \n",
       "1496  ['please', 'get', 'vaccinated', 'disclaimer', ...   \n",
       "1497  ['disappointed', 'blame', 'vaccinated', 'crowd...   \n",
       "1498  ['fair', 'cac', 'et_al', 'always', 'say', 'pfi...   \n",
       "1499  ['twentynine', 'day', 'since', 'first', 'pfize...   \n",
       "\n",
       "                      words_processed_noun_adj_verb_adv  \\\n",
       "0     ['cher', 'get', 'second', 'pfizer', 'vaccine',...   \n",
       "1                                           ['syringe']   \n",
       "2                          ['double', 'shot', 'pfizer']   \n",
       "3     ['couple', 'thing', 'wife', 'take', 'plaquenil...   \n",
       "4                           ['great', 'pfizer', 'shot']   \n",
       "...                                                 ...   \n",
       "1495  ['north', 'today', 'come', 'get', 'free', 'pfi...   \n",
       "1496  ['get', 'vaccinated', 'disclaimer', 'pfizer', ...   \n",
       "1497  ['disappointed', 'blame', 'vaccinated', 'crowd...   \n",
       "1498  ['fair', 'cac', 'et_al', 'always', 'say', 'pfi...   \n",
       "1499  ['twentynine', 'day', 'first', 'pfizer', 'shoo...   \n",
       "\n",
       "                                   words_processed_noun  \\\n",
       "0     ['cher', 'pfizer', 'vaccine', 'cher', 'guess',...   \n",
       "1                                           ['syringe']   \n",
       "2                                    ['shot', 'pfizer']   \n",
       "3     ['couple', 'thing', 'wife', 'plaquenil', 'prob...   \n",
       "4                                    ['pfizer', 'shot']   \n",
       "...                                                 ...   \n",
       "1495  ['north', 'today', 'pfizer', 'vaccine', 'year'...   \n",
       "1496                  ['disclaimer', 'pfizer', 'stock']   \n",
       "1497     ['blame', 'delta', 'covid', 'case', 'vaccine']   \n",
       "1498  ['cac', 'et_al', 'pfizer', 'vaccination', 'cha...   \n",
       "1499  ['twentynine', 'day', 'pfizer', 'day', 'shot',...   \n",
       "\n",
       "                                                 scores  compound sentiment  \n",
       "0     {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  \n",
       "1     {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  \n",
       "2     {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  \n",
       "3     {'neg': 0.056, 'neu': 0.887, 'pos': 0.057, 'co...    0.0150   neutral  \n",
       "4     {'neg': 0.0, 'neu': 0.594, 'pos': 0.406, 'comp...    0.6249  positive  \n",
       "...                                                 ...       ...       ...  \n",
       "1495  {'neg': 0.0, 'neu': 0.845, 'pos': 0.155, 'comp...    0.5106  positive  \n",
       "1496  {'neg': 0.0, 'neu': 0.753, 'pos': 0.247, 'comp...    0.3182  positive  \n",
       "1497  {'neg': 0.174, 'neu': 0.727, 'pos': 0.099, 'co...   -0.4753  negative  \n",
       "1498  {'neg': 0.0, 'neu': 0.888, 'pos': 0.112, 'comp...    0.5106  positive  \n",
       "1499  {'neg': 0.052, 'neu': 0.948, 'pos': 0.0, 'comp...   -0.2732  positive  \n",
       "\n",
       "[1500 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../usa-labelled.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486f2c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9c9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/5_1bb8ld291843m4x7vj7vnw0000gn/T/ipykernel_2417/4090771562.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['new_text_after_translation'] = df['new_text_after_translation'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "# Helper function to remove unwanted patterns\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt\n",
    "\n",
    "# Remove Twitter handles from the data \n",
    "df['new_text_after_translation'] = np.vectorize(remove_pattern)(df['new_text_after_translation'], \"@[\\w]*\")\n",
    "\n",
    "# Remove punctuations, numbers, and special characters\n",
    "df['new_text_after_translation'] = df['new_text_after_translation'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79abe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text_after_translation</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher i got my second pfizer vaccine shot may  ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syringedp ed by pfizer april relieved face</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thumbs upmedium light skin tone double shot pf...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>couple things  my wife has ra  takes plaquenil...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great  me too back april  pfizer   shots</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no side effects pfizer  x it just felt like so...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i had   doses pfizer also  sore arm day was al...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>my entire family had pfizer         all have s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>our partners at are hosting community vaccinat...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>after doing some research today  i discovered ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          new_text_after_translation sentiment\n",
       "0  cher i got my second pfizer vaccine shot may  ...   neutral\n",
       "1         syringedp ed by pfizer april relieved face   neutral\n",
       "2  thumbs upmedium light skin tone double shot pf...   neutral\n",
       "3  couple things  my wife has ra  takes plaquenil...   neutral\n",
       "4           great  me too back april  pfizer   shots  positive\n",
       "5  no side effects pfizer  x it just felt like so...  negative\n",
       "6  i had   doses pfizer also  sore arm day was al...  negative\n",
       "7  my entire family had pfizer         all have s...  negative\n",
       "8  our partners at are hosting community vaccinat...  positive\n",
       "9  after doing some research today  i discovered ...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['languages', 'new_text', 'Text', 'pos_tagged_words','words_processed_all', 'words_processed_noun_adj_verb_adv', 'words_processed_noun', 'scores','compound'], axis=1, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf5e50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text_after_translation</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher i got my second pfizer vaccine shot may  ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syringedp ed by pfizer april relieved face</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thumbs upmedium light skin tone double shot pf...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>couple things  my wife has ra  takes plaquenil...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great  me too back april  pfizer   shots</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>we       re at north high school today until  ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>y       all please get vaccinated            d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>disappointed you are blame only unvaccinated c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>be fair  cdc et al have always said pfizer or ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>if it has been    days since your first pfizer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             new_text_after_translation sentiment\n",
       "0     cher i got my second pfizer vaccine shot may  ...   neutral\n",
       "1            syringedp ed by pfizer april relieved face   neutral\n",
       "2     thumbs upmedium light skin tone double shot pf...   neutral\n",
       "3     couple things  my wife has ra  takes plaquenil...   neutral\n",
       "4              great  me too back april  pfizer   shots  positive\n",
       "...                                                 ...       ...\n",
       "1495  we       re at north high school today until  ...  positive\n",
       "1496  y       all please get vaccinated            d...  positive\n",
       "1497  disappointed you are blame only unvaccinated c...  negative\n",
       "1498  be fair  cdc et al have always said pfizer or ...  positive\n",
       "1499  if it has been    days since your first pfizer...  positive\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f44ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment2target(sentiment):\n",
    "    return {\n",
    "        'negative': 0,\n",
    "        'neutral': 1,\n",
    "        'positive' : 2\n",
    "    }[sentiment]\n",
    "targets = df.sentiment.apply(sentiment2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8905a3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text_after_translation</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher i got my second pfizer vaccine shot may  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syringedp ed by pfizer april relieved face</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thumbs upmedium light skin tone double shot pf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>couple things  my wife has ra  takes plaquenil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great  me too back april  pfizer   shots</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>we       re at north high school today until  ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>y       all please get vaccinated            d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>disappointed you are blame only unvaccinated c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>be fair  cdc et al have always said pfizer or ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>if it has been    days since your first pfizer...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             new_text_after_translation  sentiment\n",
       "0     cher i got my second pfizer vaccine shot may  ...          1\n",
       "1            syringedp ed by pfizer april relieved face          1\n",
       "2     thumbs upmedium light skin tone double shot pf...          1\n",
       "3     couple things  my wife has ra  takes plaquenil...          1\n",
       "4              great  me too back april  pfizer   shots          2\n",
       "...                                                 ...        ...\n",
       "1495  we       re at north high school today until  ...          2\n",
       "1496  y       all please get vaccinated            d...          2\n",
       "1497  disappointed you are blame only unvaccinated c...          0\n",
       "1498  be fair  cdc et al have always said pfizer or ...          2\n",
       "1499  if it has been    days since your first pfizer...          2\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] =targets\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "658d7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df['new_text_after_translation']\n",
    "y=df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a19099db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953     extremely pleased have az    st  dose   pfizer...\n",
       "121     ah  you dropped  conspiracy theory  nugget cou...\n",
       "174     which part  part where i had covid  then had m...\n",
       "525       same with me  i had issue w walgreen s  amp ...\n",
       "1082    does he realize it       s not government pfiz...\n",
       "                              ...                        \n",
       "1461    i was completely unaware pfizer booster was re...\n",
       "158         israel australia  many these have proven i...\n",
       "1232      i believe pfizer was not part warp speed anyway\n",
       "822     pffft   i m actually my  th dose already   pfizer\n",
       "764     doing better  increasing  diversity  clinicalt...\n",
       "Name: new_text_after_translation, Length: 450, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d1a38fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959     hell yeah  you not here        so yeah  good i...\n",
       "359     no i got pfizer sore arm  mild fatigue  nothin...\n",
       "661     got pfizer vaccine february  caught covid may ...\n",
       "1084    if you did this between pfizer doses  you may ...\n",
       "843     i think data will eventually show we all need ...\n",
       "                              ...                        \n",
       "1043    this was argument i used convince ppl get vacc...\n",
       "936     so  st born has autoimmune diese  i told her t...\n",
       "1378    i keep hearing delta variant has     breakthro...\n",
       "757     i think it is about time i get my covid vaccin...\n",
       "622             i didn t even get sore arm  pfizer me too\n",
       "Name: new_text_after_translation, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3572fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959     0\n",
       "359     0\n",
       "661     0\n",
       "1084    2\n",
       "843     0\n",
       "       ..\n",
       "1043    0\n",
       "936     1\n",
       "1378    1\n",
       "757     2\n",
       "622     2\n",
       "Name: sentiment, Length: 1050, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b7b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953     2\n",
       "121     0\n",
       "174     2\n",
       "525     0\n",
       "1082    1\n",
       "       ..\n",
       "1461    2\n",
       "158     2\n",
       "1232    1\n",
       "822     1\n",
       "764     2\n",
       "Name: sentiment, Length: 450, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ce357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['new_text_after_translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77039d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for a_tweet in tweets:\n",
    "            for word in a_tweet:\n",
    "                pair = (word, y)\n",
    "                if pair in freqs:\n",
    "                    freqs[pair] += 1\n",
    "                else:\n",
    "                    freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b2ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 102\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(X_train, y_train)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5cfab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # calculate the sigmoid of z\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50beac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "# Testing your function \n",
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4249f5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976294"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that when the model predicts close to 1, but the actual label is 0, the loss is a large positive value\n",
    "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "781dc95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976182"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that when the model predicts close to 0 but the actual label is 1, the loss is a large positive value\n",
    "-1 * np.log(0.0001) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05b4b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # get 'm', the number of rows in matrix x\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))\n",
    "\n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf72994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70cc9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = tweet\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eca3ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 1.19411208e+08 1.67270462e+08]]\n"
     ]
    }
   ],
   "source": [
    "# Check your function\n",
    "\n",
    "# test 1\n",
    "# test on training data\n",
    "tmp1 = extract_features(X_train[1], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1de86706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 5.1011856e+07 7.1457084e+07]]\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "# check for when the words are not in the freqs dictionary\n",
    "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6de8a297",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5_1bb8ld291843m4x7vj7vnw0000gn/T/ipykernel_2417/937338346.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# training labels corresponding to X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(X_train), 3))\n",
    "for i in range(len(X_train)):\n",
    "    X[i, :]= extract_features(X_train[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f9de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
