{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e9a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json \n",
    "import csv\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import sys\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim, spacy\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import re\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb423c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rwalk/gsdmm.git\n",
      "  Cloning https://github.com/rwalk/gsdmm.git to /private/var/folders/d0/5_1bb8ld291843m4x7vj7vnw0000gn/T/pip-req-build-4pcp086d\n",
      "  Running command git clone -q https://github.com/rwalk/gsdmm.git /private/var/folders/d0/5_1bb8ld291843m4x7vj7vnw0000gn/T/pip-req-build-4pcp086d\n",
      "  Resolved https://github.com/rwalk/gsdmm.git to commit 4ad1b6b6976743681ee4976b4573463d359214ee\n",
      "Requirement already satisfied: numpy in /Users/shaaminig/opt/anaconda3/lib/python3.9/site-packages (from gsdmm==0.1) (1.20.3)\n",
      "Building wheels for collected packages: gsdmm\n",
      "  Building wheel for gsdmm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gsdmm: filename=gsdmm-0.1-py3-none-any.whl size=4603 sha256=3715c0516cb8799c01ca93efc652613cc60f02888dce751fce509fb8ce246a7e\n",
      "  Stored in directory: /private/var/folders/d0/5_1bb8ld291843m4x7vj7vnw0000gn/T/pip-ephem-wheel-cache-cqhlbodh/wheels/81/2c/23/3ff788bcc6063bf30116ad1a06e75d3ba9aad3f7bc4aba765b\n",
      "Successfully built gsdmm\n",
      "Installing collected packages: gsdmm\n",
      "Successfully installed gsdmm-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install git+https://github.com/rwalk/gsdmm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5334f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsdmm import MovieGroupProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec1d56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../pos_neg_usa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d7f52f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>words_processed_all</th>\n",
       "      <th>words_processed_noun_adj_verb_adv</th>\n",
       "      <th>words_processed_noun</th>\n",
       "      <th>text_type</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>want find way end racism try force people inje...</td>\n",
       "      <td>['want', 'find', 'way', 'end', 'racism', 'try'...</td>\n",
       "      <td>['want', 'find', 'way', 'end', 'racism', 'try'...</td>\n",
       "      <td>['way', 'end', 'racism', 'force', 'people', 'b...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this child almost died tetanus, spent months h...</td>\n",
       "      <td>['child', 'almost', 'died', 'tetanus', 'spent'...</td>\n",
       "      <td>['child', 'almost', 'die', 'tetanus', 'spend',...</td>\n",
       "      <td>['child', 'tetanus', 'month', 'hospital', 'cos...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juste se rappeler m. leblanc la pression que l...</td>\n",
       "      <td>['remember', 'leblanc', 'pressure', 'provincia...</td>\n",
       "      <td>['remember', 'leblanc', 'pressure', 'provincia...</td>\n",
       "      <td>['leblanc', 'pressure', 'business', 'world', '...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you would expect cases rise significantly, cou...</td>\n",
       "      <td>['would', 'expect', 'case', 'rise', 'significa...</td>\n",
       "      <td>['would', 'expect', 'case', 'rise', 'significa...</td>\n",
       "      <td>['case', 'vaccination', 'rate', 'play', 'space...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depends whether vaccination status is embedded...</td>\n",
       "      <td>['depends', 'whether', 'vaccination', 'status'...</td>\n",
       "      <td>['depend', 'vaccination', 'status', 'embed', '...</td>\n",
       "      <td>['vaccination', 'status', 'code', 'link', 'con...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315598</th>\n",
       "      <td>pretty remarkable achievement. thank you all v...</td>\n",
       "      <td>['pretty', 'remarkable', 'achievement', 'thank...</td>\n",
       "      <td>['pretty', 'remarkable', 'achievement', 'thank...</td>\n",
       "      <td>['achievement', 'volunteer', 'shotsshotsshot',...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315599</th>\n",
       "      <td>oh that explains similar - seemingly out nowhe...</td>\n",
       "      <td>['explains', 'similar', 'seemingly', 'nowhere'...</td>\n",
       "      <td>['explain', 'similar', 'seemingly', 'nowhere',...</td>\n",
       "      <td>['message', 'background', 'folk', 'vaccinesave...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315600</th>\n",
       "      <td>do it others.... üí™üéâüíâü§ô #vaccinesaveslives</td>\n",
       "      <td>['others', 'vaccinesaveslives']</td>\n",
       "      <td>['other', 'vaccinesaveslive']</td>\n",
       "      <td>['other', 'vaccinesaveslive']</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315601</th>\n",
       "      <td>yay üôåüèª congrats dr. j being fully vaccinated i...</td>\n",
       "      <td>['yay', 'congrats', 'fully', 'vaccinated', 'be...</td>\n",
       "      <td>['congrat', 'fully', 'vaccinate', 'good', 'fee...</td>\n",
       "      <td>['congrat', 'feeling', 'safetyfirst', 'vaccine...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315602</th>\n",
       "      <td>we all have do our part end this pandemic‚Äî get...</td>\n",
       "      <td>['part', 'end', 'pandemic', 'get', 'vaccine', ...</td>\n",
       "      <td>['part', 'end', 'pandemic', 'get', 'vaccine', ...</td>\n",
       "      <td>['part', 'end', 'vaccine', 'help', 'other', 'v...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315603 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       want find way end racism try force people inje...   \n",
       "1       this child almost died tetanus, spent months h...   \n",
       "2       juste se rappeler m. leblanc la pression que l...   \n",
       "3       you would expect cases rise significantly, cou...   \n",
       "4       depends whether vaccination status is embedded...   \n",
       "...                                                   ...   \n",
       "315598  pretty remarkable achievement. thank you all v...   \n",
       "315599  oh that explains similar - seemingly out nowhe...   \n",
       "315600           do it others.... üí™üéâüíâü§ô #vaccinesaveslives   \n",
       "315601  yay üôåüèª congrats dr. j being fully vaccinated i...   \n",
       "315602  we all have do our part end this pandemic‚Äî get...   \n",
       "\n",
       "                                      words_processed_all  \\\n",
       "0       ['want', 'find', 'way', 'end', 'racism', 'try'...   \n",
       "1       ['child', 'almost', 'died', 'tetanus', 'spent'...   \n",
       "2       ['remember', 'leblanc', 'pressure', 'provincia...   \n",
       "3       ['would', 'expect', 'case', 'rise', 'significa...   \n",
       "4       ['depends', 'whether', 'vaccination', 'status'...   \n",
       "...                                                   ...   \n",
       "315598  ['pretty', 'remarkable', 'achievement', 'thank...   \n",
       "315599  ['explains', 'similar', 'seemingly', 'nowhere'...   \n",
       "315600                    ['others', 'vaccinesaveslives']   \n",
       "315601  ['yay', 'congrats', 'fully', 'vaccinated', 'be...   \n",
       "315602  ['part', 'end', 'pandemic', 'get', 'vaccine', ...   \n",
       "\n",
       "                        words_processed_noun_adj_verb_adv  \\\n",
       "0       ['want', 'find', 'way', 'end', 'racism', 'try'...   \n",
       "1       ['child', 'almost', 'die', 'tetanus', 'spend',...   \n",
       "2       ['remember', 'leblanc', 'pressure', 'provincia...   \n",
       "3       ['would', 'expect', 'case', 'rise', 'significa...   \n",
       "4       ['depend', 'vaccination', 'status', 'embed', '...   \n",
       "...                                                   ...   \n",
       "315598  ['pretty', 'remarkable', 'achievement', 'thank...   \n",
       "315599  ['explain', 'similar', 'seemingly', 'nowhere',...   \n",
       "315600                      ['other', 'vaccinesaveslive']   \n",
       "315601  ['congrat', 'fully', 'vaccinate', 'good', 'fee...   \n",
       "315602  ['part', 'end', 'pandemic', 'get', 'vaccine', ...   \n",
       "\n",
       "                                     words_processed_noun   text_type  \\\n",
       "0       ['way', 'end', 'racism', 'force', 'people', 'b...  subjective   \n",
       "1       ['child', 'tetanus', 'month', 'hospital', 'cos...  subjective   \n",
       "2       ['leblanc', 'pressure', 'business', 'world', '...  subjective   \n",
       "3       ['case', 'vaccination', 'rate', 'play', 'space...  subjective   \n",
       "4       ['vaccination', 'status', 'code', 'link', 'con...  subjective   \n",
       "...                                                   ...         ...   \n",
       "315598  ['achievement', 'volunteer', 'shotsshotsshot',...  subjective   \n",
       "315599  ['message', 'background', 'folk', 'vaccinesave...  subjective   \n",
       "315600                      ['other', 'vaccinesaveslive']  subjective   \n",
       "315601  ['congrat', 'feeling', 'safetyfirst', 'vaccine...  subjective   \n",
       "315602  ['part', 'end', 'vaccine', 'help', 'other', 'v...  subjective   \n",
       "\n",
       "        sentiment  \n",
       "0               2  \n",
       "1               0  \n",
       "2               0  \n",
       "3               2  \n",
       "4               2  \n",
       "...           ...  \n",
       "315598          2  \n",
       "315599          0  \n",
       "315600          2  \n",
       "315601          2  \n",
       "315602          2  \n",
       "\n",
       "[315603 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Unnamed: 0', 'index', 'new_text', 'languages', 'new_text_after_translation', 'pos_tagged_words'], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43a87b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'['"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words_processed_noun'].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84983f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25d1f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_words_processed_noun = list(sent_to_words(df['words_processed_noun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52999524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_processed_noun'] = tokens_words_processed_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00e27d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'way'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words_processed_noun'].values[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456aa556",
   "metadata": {},
   "source": [
    "# GSDMM for the topic modeling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50dce2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fe21fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['health', 'choice', 'other', 'risk', 'exposure', 'system', 'herd_immunity']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['words_processed_noun'].iloc[224817]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f3da4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315603 entries, 0 to 315602\n",
      "Data columns (total 6 columns):\n",
      " #   Column                             Non-Null Count   Dtype \n",
      "---  ------                             --------------   ----- \n",
      " 0   Text                               315603 non-null  object\n",
      " 1   words_processed_all                315603 non-null  object\n",
      " 2   words_processed_noun_adj_verb_adv  315603 non-null  object\n",
      " 3   words_processed_noun               315603 non-null  object\n",
      " 4   text_type                          315603 non-null  object\n",
      " 5   sentiment                          315603 non-null  int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # no empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28f26847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    222780\n",
       "0     92823\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5796398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = df[df['sentiment'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d1de4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>words_processed_all</th>\n",
       "      <th>words_processed_noun_adj_verb_adv</th>\n",
       "      <th>words_processed_noun</th>\n",
       "      <th>text_type</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>want find way end racism try force people inje...</td>\n",
       "      <td>['want', 'find', 'way', 'end', 'racism', 'try'...</td>\n",
       "      <td>['want', 'find', 'way', 'end', 'racism', 'try'...</td>\n",
       "      <td>[way, end, racism, force, people, bunch, peopl...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you would expect cases rise significantly, cou...</td>\n",
       "      <td>['would', 'expect', 'case', 'rise', 'significa...</td>\n",
       "      <td>['would', 'expect', 'case', 'rise', 'significa...</td>\n",
       "      <td>[case, vaccination, rate, play, space, adult, ...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depends whether vaccination status is embedded...</td>\n",
       "      <td>['depends', 'whether', 'vaccination', 'status'...</td>\n",
       "      <td>['depend', 'vaccination', 'status', 'embed', '...</td>\n",
       "      <td>[vaccination, status, code, link, connect, end...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it could have ripped‚Ä¶ harder or do you think m...</td>\n",
       "      <td>['could', 'ripped', 'harder', 'think', 'maskin...</td>\n",
       "      <td>['could', 'rip', 'hard', 'think', 'mask', 'iso...</td>\n",
       "      <td>[isolation, question, look, spike, matter, vac...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>they do this at vaccination centres as well. t...</td>\n",
       "      <td>['vaccination', 'center', 'well', 'refused', '...</td>\n",
       "      <td>['vaccination', 'center', 'well', 'refuse', 'l...</td>\n",
       "      <td>[vaccination, center, parent, mask, amp, amp, ...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315597</th>\n",
       "      <td>contrary american belief, vaccine is not perso...</td>\n",
       "      <td>['contrary', 'american', 'belief', 'vaccine', ...</td>\n",
       "      <td>['contrary', 'vaccine', 'personal', 'choice', ...</td>\n",
       "      <td>[vaccine, choice, people, risk, vaccine, part]</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315598</th>\n",
       "      <td>pretty remarkable achievement. thank you all v...</td>\n",
       "      <td>['pretty', 'remarkable', 'achievement', 'thank...</td>\n",
       "      <td>['pretty', 'remarkable', 'achievement', 'thank...</td>\n",
       "      <td>[achievement, volunteer, shotsshotsshot, fauci...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315600</th>\n",
       "      <td>do it others.... üí™üéâüíâü§ô #vaccinesaveslives</td>\n",
       "      <td>['others', 'vaccinesaveslives']</td>\n",
       "      <td>['other', 'vaccinesaveslive']</td>\n",
       "      <td>[other]</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315601</th>\n",
       "      <td>yay üôåüèª congrats dr. j being fully vaccinated i...</td>\n",
       "      <td>['yay', 'congrats', 'fully', 'vaccinated', 'be...</td>\n",
       "      <td>['congrat', 'fully', 'vaccinate', 'good', 'fee...</td>\n",
       "      <td>[congrat, feeling, safetyfirst]</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315602</th>\n",
       "      <td>we all have do our part end this pandemic‚Äî get...</td>\n",
       "      <td>['part', 'end', 'pandemic', 'get', 'vaccine', ...</td>\n",
       "      <td>['part', 'end', 'pandemic', 'get', 'vaccine', ...</td>\n",
       "      <td>[part, end, vaccine, help, other, vaccine, tod...</td>\n",
       "      <td>subjective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222780 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "0       want find way end racism try force people inje...   \n",
       "3       you would expect cases rise significantly, cou...   \n",
       "4       depends whether vaccination status is embedded...   \n",
       "5       it could have ripped‚Ä¶ harder or do you think m...   \n",
       "6       they do this at vaccination centres as well. t...   \n",
       "...                                                   ...   \n",
       "315597  contrary american belief, vaccine is not perso...   \n",
       "315598  pretty remarkable achievement. thank you all v...   \n",
       "315600           do it others.... üí™üéâüíâü§ô #vaccinesaveslives   \n",
       "315601  yay üôåüèª congrats dr. j being fully vaccinated i...   \n",
       "315602  we all have do our part end this pandemic‚Äî get...   \n",
       "\n",
       "                                      words_processed_all  \\\n",
       "0       ['want', 'find', 'way', 'end', 'racism', 'try'...   \n",
       "3       ['would', 'expect', 'case', 'rise', 'significa...   \n",
       "4       ['depends', 'whether', 'vaccination', 'status'...   \n",
       "5       ['could', 'ripped', 'harder', 'think', 'maskin...   \n",
       "6       ['vaccination', 'center', 'well', 'refused', '...   \n",
       "...                                                   ...   \n",
       "315597  ['contrary', 'american', 'belief', 'vaccine', ...   \n",
       "315598  ['pretty', 'remarkable', 'achievement', 'thank...   \n",
       "315600                    ['others', 'vaccinesaveslives']   \n",
       "315601  ['yay', 'congrats', 'fully', 'vaccinated', 'be...   \n",
       "315602  ['part', 'end', 'pandemic', 'get', 'vaccine', ...   \n",
       "\n",
       "                        words_processed_noun_adj_verb_adv  \\\n",
       "0       ['want', 'find', 'way', 'end', 'racism', 'try'...   \n",
       "3       ['would', 'expect', 'case', 'rise', 'significa...   \n",
       "4       ['depend', 'vaccination', 'status', 'embed', '...   \n",
       "5       ['could', 'rip', 'hard', 'think', 'mask', 'iso...   \n",
       "6       ['vaccination', 'center', 'well', 'refuse', 'l...   \n",
       "...                                                   ...   \n",
       "315597  ['contrary', 'vaccine', 'personal', 'choice', ...   \n",
       "315598  ['pretty', 'remarkable', 'achievement', 'thank...   \n",
       "315600                      ['other', 'vaccinesaveslive']   \n",
       "315601  ['congrat', 'fully', 'vaccinate', 'good', 'fee...   \n",
       "315602  ['part', 'end', 'pandemic', 'get', 'vaccine', ...   \n",
       "\n",
       "                                     words_processed_noun   text_type  \\\n",
       "0       [way, end, racism, force, people, bunch, peopl...  subjective   \n",
       "3       [case, vaccination, rate, play, space, adult, ...  subjective   \n",
       "4       [vaccination, status, code, link, connect, end...  subjective   \n",
       "5       [isolation, question, look, spike, matter, vac...  subjective   \n",
       "6       [vaccination, center, parent, mask, amp, amp, ...  subjective   \n",
       "...                                                   ...         ...   \n",
       "315597     [vaccine, choice, people, risk, vaccine, part]  subjective   \n",
       "315598  [achievement, volunteer, shotsshotsshot, fauci...  subjective   \n",
       "315600                                            [other]  subjective   \n",
       "315601                    [congrat, feeling, safetyfirst]  subjective   \n",
       "315602  [part, end, vaccine, help, other, vaccine, tod...  subjective   \n",
       "\n",
       "        sentiment  \n",
       "0               2  \n",
       "3               2  \n",
       "4               2  \n",
       "5               2  \n",
       "6               2  \n",
       "...           ...  \n",
       "315597          2  \n",
       "315598          2  \n",
       "315600          2  \n",
       "315601          2  \n",
       "315602          2  \n",
       "\n",
       "[222780 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d6ec8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'['"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df['words_processed_all'].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61e521fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokenised_lemmatized = list(sent_to_words(positive_df['words_processed_all']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d66845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'want'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tokenised_lemmatized[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96da1859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222780"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_tokenised_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26cff546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster,sort_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff96b05",
   "metadata": {},
   "source": [
    "### Cluster size: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81f59853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 159315 clusters with 4 clusters populated\n",
      "In stage 1: transferred 126370 clusters with 4 clusters populated\n",
      "In stage 2: transferred 64092 clusters with 4 clusters populated\n",
      "In stage 3: transferred 41222 clusters with 4 clusters populated\n",
      "In stage 4: transferred 33640 clusters with 4 clusters populated\n",
      "In stage 5: transferred 31111 clusters with 4 clusters populated\n",
      "In stage 6: transferred 29819 clusters with 4 clusters populated\n",
      "In stage 7: transferred 29371 clusters with 4 clusters populated\n",
      "In stage 8: transferred 29008 clusters with 4 clusters populated\n",
      "In stage 9: transferred 28927 clusters with 4 clusters populated\n",
      "In stage 10: transferred 28788 clusters with 4 clusters populated\n",
      "In stage 11: transferred 28769 clusters with 4 clusters populated\n",
      "In stage 12: transferred 28520 clusters with 4 clusters populated\n",
      "In stage 13: transferred 28530 clusters with 4 clusters populated\n",
      "In stage 14: transferred 28644 clusters with 4 clusters populated\n",
      "In stage 15: transferred 28597 clusters with 4 clusters populated\n",
      "In stage 16: transferred 28633 clusters with 4 clusters populated\n",
      "In stage 17: transferred 28590 clusters with 4 clusters populated\n",
      "In stage 18: transferred 28717 clusters with 4 clusters populated\n",
      "In stage 19: transferred 28544 clusters with 4 clusters populated\n",
      "In stage 20: transferred 28507 clusters with 4 clusters populated\n",
      "In stage 21: transferred 28716 clusters with 4 clusters populated\n",
      "In stage 22: transferred 28897 clusters with 4 clusters populated\n",
      "In stage 23: transferred 28783 clusters with 4 clusters populated\n",
      "In stage 24: transferred 28966 clusters with 4 clusters populated\n",
      "In stage 25: transferred 28882 clusters with 4 clusters populated\n",
      "In stage 26: transferred 29013 clusters with 4 clusters populated\n",
      "In stage 27: transferred 28964 clusters with 4 clusters populated\n",
      "In stage 28: transferred 28861 clusters with 4 clusters populated\n",
      "In stage 29: transferred 28952 clusters with 4 clusters populated\n"
     ]
    }
   ],
   "source": [
    "mgp = MovieGroupProcess(K=4, alpha=0.1, beta=0.2, n_iters=30)\n",
    "\n",
    "vocab = set(x for review in positive_tokenised_lemmatized for x in review)\n",
    "n_terms = len(vocab)\n",
    "model = mgp.fit(positive_tokenised_lemmatized, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f90c5e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [41915 52917 48689 79259]\n",
      "\n",
      "Most important clusters (by number of docs inside): [3 1 2 0]\n",
      "\n",
      "Cluster 3 : [('vaccinated', 40985), ('not', 26859), ('vaccine', 25124), ('get', 22642), ('people', 19030), ('mask', 15529), ('vaccinate', 11522), ('mandate', 10789), ('couid', 10727), ('anti', 10125)]\n",
      "\n",
      "Cluster 1 : [('get', 31069), ('pfizer', 23031), ('modern', 19102), ('shot', 15856), ('booster', 15019), ('vaccine', 12967), ('dose', 10937), ('shoot', 9965), ('day', 9175), ('two', 9077)]\n",
      "\n",
      "Cluster 2 : [('vaccinated', 27830), ('vaccine', 23679), ('couid', 17822), ('not', 16421), ('get', 15948), ('people', 14126), ('vaccinate', 10800), ('effective', 7549), ('one', 6656), ('still', 5945)]\n",
      "\n",
      "Cluster 0 : [('vaccine', 24214), ('pfizer', 20951), ('modern', 9662), ('not', 8940), ('get', 6463), ('amp', 5721), ('one', 5614), ('dose', 4054), ('people', 3478), ('couid', 3406)]\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "# topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('\\nMost important clusters (by number of docs inside):', top_index)\n",
    "# show the top 5 words in term frequency for each cluster \n",
    "top_words(mgp.cluster_word_distribution, top_index, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72b6193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don`t rename the clusters\n",
    "\n",
    "topic_dict = {}\n",
    "topic_names = ['type 1',\n",
    "               'type 2',\n",
    "               'type 3',\n",
    "               'type 4'\n",
    "              ]\n",
    "for i, topic_num in enumerate(top_index):\n",
    "    topic_dict[topic_num]=topic_names[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db7d3cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topics_dataframe(data_text=positive_df.Text,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, lemma_text=positive_tokenised_lemmatized):\n",
    "    result = pd.DataFrame(columns=['Text', 'Topic', 'Lemma-text'])\n",
    "    for i, text in enumerate(data_text):\n",
    "        result.at[i, 'Text'] = text\n",
    "        result.at[i, 'Lemma-text'] = lemma_text[i]\n",
    "        prob = mgp.choose_best_label(positive_tokenised_lemmatized[i])\n",
    "        if prob[1] >= threshold:\n",
    "            result.at[i, 'Topic'] = topic_dict[prob[0]]\n",
    "        else:\n",
    "            result.at[i, 'Topic'] = 'Other'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_topics_dataframe(data_text=positive_df.Text, mgp=mgp, threshold=0.3, topic_dict=topic_dict, lemma_text=positive_tokenised_lemmatized)\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.pie(result, names='Topic',  title='Topics', color_discrete_sequence=px.colors.sequential.Burg)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "types_counts = result.Topic.value_counts()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "types = sns.barplot(x = types_counts.index, y = types_counts.values, palette=\"pastel\", ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['len'] = result.Text.apply(lambda row: len(row.split()))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b06d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Lemma_text'] = result['Lemma-text'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f15a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop('Lemma-text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df128d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_WordCloud(data, title=None):\n",
    "    wordcloud = WordCloud(width = 500, height = 500,\n",
    "                          background_color ='white',\n",
    "                          min_font_size = 15, collocations=False\n",
    "                         ).generate(\" \".join(data.values))\n",
    "                      \n",
    "    plt.figure(figsize = (5, 5), facecolor = None) \n",
    "    plt.imshow(wordcloud, interpolation='bilinear') \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.title(title,fontsize=20)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_WordCloud(result['Lemma_text'].loc[result.Topic == 'type 1'], title=\"Most used words in topic 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_WordCloud(result['Lemma_text'].loc[result.Topic == 'type 2'], title=\"Most used words in topic 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a066568",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_WordCloud(result['Lemma_text'].loc[result.Topic == 'type 3'], title=\"Most used words in topic 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26696ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_WordCloud(result['Lemma_text'].loc[result.Topic == 'type 4'], title=\"Most used words in topic 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b016bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_WordCloud(result['Lemma_text'].loc[result.Topic == 'Other'], title=\"Most used words in Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988a296",
   "metadata": {},
   "source": [
    "### Cluster size: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12464240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgp = MovieGroupProcess(K=5, alpha=0.1, beta=0.2, n_iters=30)\n",
    "\n",
    "vocab = set(x for review in positive_tokenised_lemmatized for x in review)\n",
    "n_terms = len(vocab)\n",
    "model = mgp.fit(positive_tokenised_lemmatized, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b106379",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgp = MovieGroupProcess(K=6, alpha=0.1, beta=0.2, n_iters=30)\n",
    "\n",
    "vocab = set(x for review in positive_tokenised_lemmatized for x in review)\n",
    "n_terms = len(vocab)\n",
    "model = mgp.fit(positive_tokenised_lemmatized, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5399d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eecf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
